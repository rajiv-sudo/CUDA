{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4444835-70c4-4c0f-a9e5-8bdbacc2e605",
   "metadata": {},
   "source": [
    "## LLM Inference on G6.4xlarge EC2 Instance\n",
    "This EC2 instance has one NVIDIA L4 GPU. We will run inference on the Intel/neural-chat-7b-v3-3 model using GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2601697-2265-40ec-9a34-e6fae91be8ae",
   "metadata": {},
   "source": [
    "## Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81510468-f07a-4cb6-838e-a01e8648e75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.40.2-py3-none-any.whl (9.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in ./test/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: requests in ./test/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./test/lib/python3.10/site-packages (from transformers) (0.23.0)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: safetensors>=0.4.1 in ./test/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./test/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: filelock in ./test/lib/python3.10/site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./test/lib/python3.10/site-packages (from transformers) (24.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2024.4.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (774 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.1/774.1 KB\u001b[0m \u001b[31m80.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in ./test/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./test/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./test/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./test/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./test/lib/python3.10/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./test/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./test/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Installing collected packages: regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.4.28 tokenizers-0.19.1 transformers-4.40.2\n",
      "Requirement already satisfied: huggingface_hub in ./test/lib/python3.10/site-packages (0.23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./test/lib/python3.10/site-packages (from huggingface_hub) (4.11.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./test/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./test/lib/python3.10/site-packages (from huggingface_hub) (4.66.4)\n",
      "Requirement already satisfied: requests in ./test/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: filelock in ./test/lib/python3.10/site-packages (from huggingface_hub) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./test/lib/python3.10/site-packages (from huggingface_hub) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./test/lib/python3.10/site-packages (from huggingface_hub) (24.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./test/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./test/lib/python3.10/site-packages (from requests->huggingface_hub) (2.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./test/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./test/lib/python3.10/site-packages (from requests->huggingface_hub) (3.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -q accelerate\n",
    "!pip install transformers\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf4602-282d-4023-a496-1290e9cd3385",
   "metadata": {},
   "source": [
    "## Log into Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aeb281e-ce1c-4db3-97b8-1accc56ab1ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2669dcd663a42369166f0c4255358ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9670735-75ca-45b7-8536-0194c8bc1d63",
   "metadata": {},
   "source": [
    "## Load the model and Tokenizer from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d62612da-232a-4639-8dd3-bd8959214846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/test/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc88fc2cdbcd481ea7b5e2c7448a7ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/test/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5c6ea209ca4be59e99bf8cf7169ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba88a68e78e7425aa5f9b0ffaec87b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34c5f5f50444da9b9395b01c218f284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f785541442bf4a87b874d788d43a29e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe87271edb9484d92bbc732142fae58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0648242c2743b0a46f5bd2511826b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e14645600b714b7d9d169e5283a8f174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/953 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e41fe123814dbc87a089a4ab2c0191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a5ab9b36244357aa2944567d2b2028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783df26e2cb2442eb22a531575b21c4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a19aa5d761041f0a0ca49fe099f209d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/145 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"Intel/neural-chat-7b-v3-3\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfda04a-e64d-48ac-967f-f734bb417e5b",
   "metadata": {},
   "source": [
    "## Run the inference on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b7c42ca-98fb-47d4-90b2-237298be7505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write be a 150 word essay Why is health important to everyone?\n",
      "\n",
      "Health is the most valuable asset that every individual possesses. It is the foundation upon which our lives are built, allowing us to pursue our dreams, goals, and aspirations. Without good health, our ability to function effectively in various aspects of life, such as work, relationships, and personal growth, is severely compromised.\n",
      "\n",
      "Health encompasses not only physical well-being but also mental, emotional, and social wellness. It is a holistic concept that requires a balanced approach to maintain. A healthy lifestyle involves making conscious choices about diet, exercise, sleep, stress management, and overall self-care.\n",
      "\n",
      "The importance of health cannot be overstated. It is the key to our happiness, productivity, and overall quality of life. Good health enables us to be more resilient in the face of challenges, both physical and emotional. It also helps us to build stronger relationships with others, as we are better equipped to support and care for those around us.\n",
      "\n",
      "Investing in our health is an investment in our future. By prioritizing our well-being, we can ensure that we are able to continue living life to the fullest, pursuing our passions and dreams without being hindered by illness or disease. Ultimately, health is the cornerstone of a fulfilling and meaningful existence, and its value cannot be underestimated.\n",
      "Number of tokens generated:  299\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "text = \"Write be a 150 word essay Why is health important to everyone?\"\n",
    "device = \"cuda\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Get start time\n",
    "t1 = time.time()\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=300)\n",
    "\n",
    "# Get end time\n",
    "t2 = time.time()\n",
    "\n",
    "# Get total time taken\n",
    "t3 = t2 - t1\n",
    "\n",
    "response = (tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "print(response)\n",
    "\n",
    "# Calculate the number of output tokens\n",
    "tokens = tokenizer.tokenize(response)\n",
    "num_tokens = (len(tokens))\n",
    "print(\"Number of tokens generated: \", num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e5e7f-6449-4093-ae67-5f1fd1bf8964",
   "metadata": {},
   "source": [
    "## Calculate Throughput and total time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a786c73f-2b8b-4ce2-8c05-e0cecccbd08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.871081352233887 : seconds\n",
      "Number of Tokens per second:  16.73094056855295\n"
     ]
    }
   ],
   "source": [
    "# Print total time taken\n",
    "print(t3,\": seconds\")\n",
    "\n",
    "# Calculate tokens per secon\n",
    "tokens_per_second = num_tokens/t3\n",
    "\n",
    "print(\"Number of Tokens per second: \", tokens_per_second)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abf3500-345d-4a04-91b9-52d371e9187b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
